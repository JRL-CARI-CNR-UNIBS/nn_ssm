ssm_nn:
  inputs: 2
  layer0:
    activation: sigmoid
    bias:
    - 0.4237595796585083
    - 0.046410929411649704
    nodes: 2
    weights:
    - 0.12724031507968903
    - 0.10320734977722168
    - -0.6292276382446289
    - 0.5205326080322266
  layer1:
    activation: sigmoid
    bias:
    - 0.012017836794257164
    - -0.27228179574012756
    nodes: 2
    weights:
    - -0.3927179276943207
    - 0.012694714590907097
    - -0.3491166830062866
    - -0.34451761841773987
